{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24e1ee-b2a8-4bfb-93b2-8e989e328a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "# No 'google.colab' import needed for local Jupyter Notebooks\n",
    "\n",
    "def process_image(img_raw):\n",
    "    \"\"\"\n",
    "    Processes a single image using DBSCAN for segmentation.\n",
    "    Returns the original, grayscale, and clustered (enhanced) images.\n",
    "    \"\"\"\n",
    "    if img_raw is None:\n",
    "        print(\"Error: Input image is None.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 1. Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_raw, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 3. Create feature vectors for each pixel (row, col, intensity)\n",
    "    rows, cols = blurred.shape\n",
    "    features = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            features.append([r, c, blurred[r, c]])\n",
    "    features = np.array(features)\n",
    "\n",
    "    # 4. Apply DBSCAN clustering\n",
    "    # Parameters might need fine-tuning for different image sets\n",
    "    # Experiment with these values if your segmentation isn't optimal\n",
    "    dbscan = DBSCAN(eps=5, min_samples=38) \n",
    "    clusters = dbscan.fit_predict(features)\n",
    "\n",
    "    # 5. Reshape the cluster labels to the original image dimensions\n",
    "    clustered_image = clusters.reshape((rows, cols))\n",
    "\n",
    "    # 6. Create a colored output image (white background)\n",
    "    output_img = np.ones_like(img_raw) * 255\n",
    "\n",
    "    # 7. Color the largest non-noise cluster black\n",
    "    unique_labels, counts = np.unique(clustered_image, return_counts=True)\n",
    "    \n",
    "    # Exclude noise label (-1) from consideration\n",
    "    non_noise_labels = unique_labels[unique_labels != -1]\n",
    "    \n",
    "    if len(non_noise_labels) > 0:\n",
    "        # Find the largest non-noise cluster by count\n",
    "        largest_cluster_label = non_noise_labels[np.argmax(counts[unique_labels != -1])]\n",
    "        mask = (clustered_image == largest_cluster_label)\n",
    "        output_img[mask] = [0, 0, 0] # Color the largest cluster black\n",
    "    else:\n",
    "        print(\"No significant clusters found other than noise. Output image will be mostly white.\")\n",
    "\n",
    "    return img_raw, gray, output_img\n",
    "\n",
    "def calculate_simple_accuracy(enhanced_img, original_gray_img):\n",
    "    \"\"\"\n",
    "    Calculates a simple 'accuracy' score based on the proportion of\n",
    "    black pixels in the enhanced image relative to the overall image size.\n",
    "    This is a proxy for segmentation quality, as no ground truth masks are provided.\n",
    "    A higher score indicates a larger segmented (black) area.\n",
    "    \"\"\"\n",
    "    # Count black pixels in the enhanced image (assuming black is [0,0,0])\n",
    "    black_pixels = np.sum(np.all(enhanced_img == [0, 0, 0], axis=-1))\n",
    "    total_pixels = enhanced_img.shape[0] * enhanced_img.shape[1]\n",
    "    \n",
    "    # Calculate a normalized score for segmented area\n",
    "    segmentation_ratio = black_pixels / total_pixels\n",
    "    \n",
    "    return segmentation_ratio\n",
    "\n",
    "def plot_histogram_with_centroids(image, title, ax):\n",
    "    \"\"\"\n",
    "    Generates a histogram for a grayscale image and plots centroid positions.\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3: # If it's a BGR image, convert to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image # Already grayscale\n",
    "\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    ax.plot(hist, color='black')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Pixel Intensity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Calculate and plot centroid (mean intensity value)\n",
    "    flat_image = gray_image.flatten()\n",
    "    if len(flat_image) > 0:\n",
    "        centroid = np.mean(flat_image)\n",
    "        ax.axvline(centroid, color='red', linestyle='dashed', linewidth=1)\n",
    "        ax.text(centroid + 5, ax.get_ylim()[1] * 0.9, f'Centroid: {centroid:.2f}', color='red')\n",
    "\n",
    "\n",
    "# --- Main execution block for Jupyter Notebook (Local) ---\n",
    "\n",
    "# 1. Get Zip File Path from User Input\n",
    "zip_file_path = input(\"Please enter the full path to your zip file (e.g., C:\\\\Users\\\\YourName\\\\images.zip): \").strip()\n",
    "# On Windows, input() might include quotes if you drag-and-drop. Remove them.\n",
    "if zip_file_path.startswith(\"'\") and zip_file_path.endswith(\"'\"):\n",
    "    zip_file_path = zip_file_path[1:-1]\n",
    "elif zip_file_path.startswith('\"') and zip_file_path.endswith('\"'):\n",
    "    zip_file_path = zip_file_path[1:-1]\n",
    "\n",
    "\n",
    "enhanced_images_data = []\n",
    "image_names = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create a directory to save enhanced images\n",
    "output_dir = \"enhanced_images_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        raise FileNotFoundError(f\"Zip file not found at: {zip_file_path}\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
    "        # Filter for common image file extensions\n",
    "        image_files = [f for f in zf.namelist() if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
    "        \n",
    "        if not image_files:\n",
    "            print(\"No image files found in the zip archive.\")\n",
    "        else:\n",
    "            print(f\"Found {len(image_files)} image(s) in the zip file.\")\n",
    "            \n",
    "            # Process up to 5 images\n",
    "            images_to_process = image_files[:5]\n",
    "            if len(image_files) > 5:\n",
    "                print(f\"Note: Processing only the first {len(images_to_process)} images found in the zip file.\")\n",
    "\n",
    "            for img_name in images_to_process:\n",
    "                print(f\"\\nProcessing {img_name}...\")\n",
    "                with zf.open(img_name) as img_file:\n",
    "                    img_data = img_file.read()\n",
    "                    img_array = np.frombuffer(img_data, np.uint8)\n",
    "                    img_raw = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "                    if img_raw is None:\n",
    "                        print(f\"Warning: Could not decode image {img_name}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    original_img, gray_img, enhanced_img = process_image(img_raw)\n",
    "                    \n",
    "                    if enhanced_img is not None:\n",
    "                        enhanced_images_data.append((original_img, enhanced_img, gray_img))\n",
    "                        image_names.append(img_name)\n",
    "                        \n",
    "                        # Calculate and store accuracy\n",
    "                        accuracy = calculate_simple_accuracy(enhanced_img, gray_img)\n",
    "                        accuracy_scores.append(accuracy)\n",
    "                        \n",
    "                        # Save the enhanced image to the output directory\n",
    "                        base_name = os.path.splitext(os.path.basename(img_name))[0]\n",
    "                        output_path = os.path.join(output_dir, f\"enhanced_{base_name}.png\")\n",
    "                        cv2.imwrite(output_path, enhanced_img)\n",
    "                        print(f\"Enhanced image saved to {output_path}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Error: '{zip_file_path}' is not a valid zip file. Please check your file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# --- Display Results in Jupyter Notebook ---\n",
    "\n",
    "if not enhanced_images_data:\n",
    "    print(\"No images were successfully processed to display results.\")\n",
    "else:\n",
    "    # 1. Display all enhanced images (Original vs. Enhanced)\n",
    "    print(\"\\n--- Original vs. Enhanced Images ---\")\n",
    "    plt.figure(figsize=(15, 6 * len(enhanced_images_data)))\n",
    "    for i, (original, enhanced, _) in enumerate(enhanced_images_data):\n",
    "        plt.subplot(len(enhanced_images_data), 2, 2*i + 1)\n",
    "        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Original: {image_names[i]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(len(enhanced_images_data), 2, 2*i + 2)\n",
    "        plt.imshow(enhanced)\n",
    "        plt.title(f'Enhanced: {image_names[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Bar chart of \"Accuracy\" (Segmentation Ratio)\n",
    "    print(\"\\n--- Segmentation Ratio Bar Chart ---\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_positions = np.arange(len(image_names))\n",
    "    plt.bar(bar_positions, accuracy_scores, color='skyblue')\n",
    "    plt.xlabel('Image Name')\n",
    "    plt.ylabel('Segmentation Ratio (Proxy for Accuracy)')\n",
    "    plt.title('Segmentation Ratio for Each Processed Image')\n",
    "    # Use basename for cleaner labels on the x-axis\n",
    "    plt.xticks(bar_positions, [os.path.basename(name) for name in image_names], rotation=45, ha='right')\n",
    "    plt.ylim(0, 1) # Accuracy/ratio is typically between 0 and 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Histograms with Centroids for Original Grayscale and Enhanced Images\n",
    "    print(\"\\n--- Histograms with Centroids ---\")\n",
    "    num_images = len(enhanced_images_data)\n",
    "    # Adjust subplot grid based on number of images\n",
    "    fig_histograms, axes_hist = plt.subplots(num_images, 2, figsize=(15, 5 * num_images))\n",
    "    \n",
    "    # Ensure axes_hist is always a 2D array for consistent indexing\n",
    "    if num_images == 1:\n",
    "        axes_hist = np.array([axes_hist]) # Make it a 2D array for consistent indexing [i, 0] and [i, 1]\n",
    "\n",
    "    for i, (original, enhanced, gray) in enumerate(enhanced_images_data):\n",
    "        # Histogram for Original Grayscale Image\n",
    "        plot_histogram_with_centroids(gray, f'Original Histogram: {os.path.basename(image_names[i])}', axes_hist[i, 0])\n",
    "        \n",
    "        # Histogram for Enhanced Image (convert to grayscale first for histogram calculation)\n",
    "        enhanced_gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
    "        plot_histogram_with_centroids(enhanced_gray, f'Enhanced Histogram: {os.path.basename(image_names[i])}', axes_hist[i, 1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63e01a-2fb6-4a07-85b7-feaafdcfbd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
